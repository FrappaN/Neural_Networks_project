{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Robustness of Interpretability Methods through Explanation Invariance and Equivariance'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper which I am re-implementing introduce an evaluation metric to test the robustness of the explanation. \n",
    "\n",
    "The quality of robustness is tipically associated to the idea that, when performing a transformation to the input, the explanation should not change significantly (see e.g. the \"continuity\" evaluation in Nauta et al. 2023). In this work, they focus on transformations based on symmetries which are respected by the models. The assumption is that, if the output of a model is invariant under a certain symmetry, the corresponding explanation should also be invariant or equivariant, depending on the type of explanation.\n",
    "\n",
    "The example I focus in this re-implementation is that of Graph Neural Networks. Many of these models, in the case of graph-level tasks, are notoriously invariant under node permutation, i.e. the output remains the same. A corresponding attribution on the node features should therefore be equivariant under a node permutation: the important features of a specific node should remain the same. In other words, given a fixed node permutation $P$ and a graph $G$, the explanation of a permuted graph $e(P(G))$, and the permuted explanation of the original graph $P'(e(G))$ should be the same (where $P$ and $P'$ might be differently defined depending on the domain of the explanation, but corresponding to the same permuation).\n",
    "\n",
    "When the attribution does not respect the original symmetry, the authors also propose a systematic approach to make an attribution more robust, by aggregrating all the explanations produced when performing all possible transformations in a given symmetry group on the data. They prove that the attribution produced in this way should always be equivariant. However, as in the case of node permutations, the number of possible transformations can very large, even if finite, and the equivariant explanation can only be approximated by a Monte Carlo estimation.\n",
    "\n",
    "In this example, I test the equivariance requirement on 4 attribution explainers: GNNExplainer, Integrated Gradients, Deconvolution and GradientSHAP. I reproduce the original model and test of the paper and the main result of their experiment with a GNN trained on the Mutagenicity dataset. Moreover, since GradientSHAP shows to be not equivariant, I also test the proposed method to enforce equivariant explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francescopaolonerini/anaconda3/envs/pyg/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import of libraries and utilities\n",
    "\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from torch_geometric import seed_everything\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "# import of my code\n",
    "from dataloader import load_mutagenicity\n",
    "from model import MUTAG_GNN\n",
    "from explainers import *\n",
    "from train import train, accuracy\n",
    "from utils import equivariance_robustness\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of data, model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading of mutagenicity dataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "trainloader, testloader = load_mutagenicity(device=device, seed = 3003)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 1.337838888168335; Test loss: 0.8272989392280579; Test accuracy: 0.5607833771196561\n",
      "Epoch 1 - Training loss: 0.6814165115356445; Test loss: 0.6713846921920776; Test accuracy: 0.5741581084308575\n",
      "Epoch 2 - Training loss: 0.6369482278823853; Test loss: 0.6497127413749695; Test accuracy: 0.619775495581562\n",
      "Epoch 3 - Training loss: 0.5818501710891724; Test loss: 0.6309210658073425; Test accuracy: 0.6345832338189634\n",
      "Epoch 4 - Training loss: 0.5405450463294983; Test loss: 0.6355844736099243; Test accuracy: 0.6319560544542632\n",
      "Epoch 5 - Training loss: 0.5092921257019043; Test loss: 0.6490525007247925; Test accuracy: 0.6419871029376641\n",
      "Epoch 6 - Training loss: 0.5016511678695679; Test loss: 0.6736912727355957; Test accuracy: 0.6384045856221638\n",
      "Epoch 7 - Training loss: 0.4936051368713379; Test loss: 0.6723114252090454; Test accuracy: 0.6431812753761643\n",
      "Epoch 8 - Training loss: 0.47835737466812134; Test loss: 0.6605879664421082; Test accuracy: 0.6563171721996657\n",
      "Epoch 9 - Training loss: 0.46461933851242065; Test loss: 0.6633641123771667; Test accuracy: 0.6625268688798662\n",
      "Epoch 10 - Training loss: 0.45644110441207886; Test loss: 0.6665019392967224; Test accuracy: 0.6663482206830666\n",
      "Epoch 11 - Training loss: 0.4497404098510742; Test loss: 0.6783913373947144; Test accuracy: 0.6646763792691665\n",
      "Epoch 12 - Training loss: 0.44624805450439453; Test loss: 0.6908345222473145; Test accuracy: 0.6651540482445665\n",
      "Epoch 13 - Training loss: 0.44023197889328003; Test loss: 0.7066441774368286; Test accuracy: 0.6639598758060664\n",
      "Epoch 14 - Training loss: 0.43124741315841675; Test loss: 0.7062366604804993; Test accuracy: 0.6670647241461667\n",
      "Epoch 15 - Training loss: 0.4204562306404114; Test loss: 0.6856788396835327; Test accuracy: 0.6754239312156676\n",
      "Epoch 16 - Training loss: 0.40366801619529724; Test loss: 0.6740691661834717; Test accuracy: 0.6785287795557678\n",
      "Epoch 17 - Training loss: 0.391632616519928; Test loss: 0.688145101070404; Test accuracy: 0.6811559589204681\n",
      "Epoch 18 - Training loss: 0.38833141326904297; Test loss: 0.6860167384147644; Test accuracy: 0.6811559589204681\n",
      "Epoch 19 - Training loss: 0.3950485587120056; Test loss: 0.7234113216400146; Test accuracy: 0.6751850967279676\n",
      "Epoch 20 - Training loss: 0.40835627913475037; Test loss: 0.7193251252174377; Test accuracy: 0.6720802483878672\n",
      "Epoch 21 - Training loss: 0.4090438783168793; Test loss: 0.7934327125549316; Test accuracy: 0.6627657033675662\n",
      "Epoch 22 - Training loss: 0.38984084129333496; Test loss: 0.752240777015686; Test accuracy: 0.6637210413183664\n",
      "Epoch 23 - Training loss: 0.3793143630027771; Test loss: 0.7253602743148804; Test accuracy: 0.6864103176498686\n",
      "Final accuracy on test set: 0.69\n"
     ]
    }
   ],
   "source": [
    "# training of the model, using the same parameters as in the paper\n",
    "# the early stopping is tested on the test set since \"the model generalization is never used as an evaluation criterion.\"\n",
    "# (they literally wrote this in the paper)\n",
    "\n",
    "gnn = MUTAG_GNN()\n",
    "gnn.to(device)\n",
    "\n",
    "logs = train(gnn, trainloader, testloader, epochs=200, lr=1e-3, weight_decay=1e-5, patience=20)\n",
    "\n",
    "gnn.eval()\n",
    "\n",
    "print('Final accuracy on test set: {:.2f}'.format(accuracy(gnn, testloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing explainers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use four explainers: GNNExplainer, Integrated Gradients, GradientShap and Deconvolution\n",
    "# GNNExplainer and Deconvolution are not used in the paper, but we include them for comparison\n",
    "\n",
    "# NOTE: GNNExplainer is very slow, and it is not recommended to run it on CPU.\n",
    "\n",
    "\n",
    "explainers = [\n",
    "    gnnexp_scores(model=gnn, device=device),\n",
    "    captum_scores(model=gnn, device=device, explainer_name='IntegratedGradients'),\n",
    "    captum_scores(model=gnn, device=device, explainer_name='GradientShap', baseline_type='zeros'),\n",
    "    captum_scores(model=gnn, device=device, explainer_name='GradientShap', baseline_type='ones'),\n",
    "    captum_scores(model=gnn, device=device, explainer_name='Deconvolution'),\n",
    "]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: GNNExplainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 2/50 [07:03<2:49:35, 211.99s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m explainer_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGradientShap\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     16\u001b[0m     explainer_name \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexplainer\u001b[38;5;241m.\u001b[39mbaseline_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 17\u001b[0m results[explainer_name] \u001b[38;5;241m=\u001b[39m equivariance_robustness(testloader, explainer)\n",
      "File \u001b[0;32m~/GitHub/Neural_Networks_project/notebooks/../src/utils.py:41\u001b[0m, in \u001b[0;36mequivariance_robustness\u001b[0;34m(loader, explainer, ntest)\u001b[0m\n\u001b[1;32m     38\u001b[0m perm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandperm(data\u001b[38;5;241m.\u001b[39mnum_nodes)\n\u001b[1;32m     39\u001b[0m data_perm \u001b[38;5;241m=\u001b[39m perm_graph(data, perm)\n\u001b[0;32m---> 41\u001b[0m attr \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mexplain(data_perm)\n\u001b[1;32m     43\u001b[0m attr_normalized \u001b[38;5;241m=\u001b[39m attr \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt((attr\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# cosine similarity between the normalized, flattened arrays.\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/Neural_Networks_project/notebooks/../src/explainers.py:33\u001b[0m, in \u001b[0;36mgnnexp_scores.explain\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexplain\u001b[39m(\u001b[38;5;28mself\u001b[39m, data ):\n\u001b[0;32m---> 33\u001b[0m     explanation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, batch\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mbatch, target\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m     34\u001b[0m     scores_features \u001b[38;5;241m=\u001b[39m explanation\u001b[38;5;241m.\u001b[39mnode_mask\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scores_features\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.11/site-packages/torch_geometric/explain/explainer.py:205\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 205\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    207\u001b[0m     x,\n\u001b[1;32m    208\u001b[0m     edge_index,\n\u001b[1;32m    209\u001b[0m     target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[1;32m    210\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    212\u001b[0m )\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain(training)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Add explainer objectives to the `Explanation` object:\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.11/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:87\u001b[0m, in \u001b[0;36mGNNExplainer.forward\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeterogeneous graphs not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train(model, x, edge_index, target\u001b[38;5;241m=\u001b[39mtarget, index\u001b[38;5;241m=\u001b[39mindex, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     89\u001b[0m node_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_mask(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_mask,\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhard_node_mask,\n\u001b[1;32m     92\u001b[0m     apply_sigmoid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     93\u001b[0m )\n\u001b[1;32m     94\u001b[0m edge_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_mask(\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_mask,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhard_edge_mask,\n\u001b[1;32m     97\u001b[0m     apply_sigmoid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     98\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.11/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:139\u001b[0m, in \u001b[0;36mGNNExplainer._train\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     y_hat, y \u001b[38;5;241m=\u001b[39m y_hat[index], y[index]\n\u001b[1;32m    137\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(y_hat, y)\n\u001b[0;32m--> 139\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    140\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# In the first iteration, we collect the nodes and edges that are\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# involved into making the prediction. These are all the nodes and\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# edges with gradient != 0 (without regularization applied).\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pyg/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "\n",
    "# we select a single batch of the test set with enogh nodes to test the equivariance robustness\n",
    "\n",
    "\n",
    "# for each explainer we compute the equivariance robustness\n",
    "# the equivariance robustness is computed with respect to the feature attribution scores \n",
    "# and averaged across the databatches in testloader\n",
    "\n",
    "\n",
    "for explainer in explainers:\n",
    "    explainer_name = explainer.explainer_name\n",
    "    print('Testing:', explainer_name)\n",
    "    if explainer_name == 'GradientShap':\n",
    "        explainer_name = f'GradientSHAP_{explainer.baseline_type}'\n",
    "    results[explainer_name] = equivariance_robustness(testloader, explainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Explanation Equivariance')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lastly we plot the results using a boxplot\n",
    "\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(data=results, ax=ax)\n",
    "\n",
    "ax.set_ylabel('Explanation Equivariance')\n",
    "\n",
    "fig.savefig('mutag_equivariance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enforcing equivariant explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [1:17:12<00:00, 92.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equivariance Robustness of GradientSHAP after correction: [0.99281033 0.99251356 0.99336271 0.99201895 0.99150314 0.99213333\n",
      " 0.99256234 0.9927558  0.99198723 0.99205179 0.99235765 0.99275369\n",
      " 0.99239187 0.99156025 0.99323458 0.99212592 0.9929313  0.99211253\n",
      " 0.99273503 0.99305533 0.99315359 0.99206559 0.99279164 0.99304292\n",
      " 0.99264633 0.99170607 0.99267672 0.99244252 0.99171457 0.99323548\n",
      " 0.99305648 0.99252417 0.99255684 0.99294789 0.9932049  0.9918775\n",
      " 0.9926032  0.9918919  0.99213602 0.99233904 0.99292224 0.99278279\n",
      " 0.9930789  0.99362934 0.99332455 0.99262502 0.9927404  0.9915994\n",
      " 0.99262228 0.99311238]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# first we define our explainer, which must have an explain method which takes the data as input\n",
    "gradientSHAP = captum_scores(model=gnn, device=device, explainer_name='GradientShap', baseline_type='zeros')\n",
    "\n",
    "# we wrap the explainer in the equivariant_explainer class, which will enforce the equivariance property\n",
    "# by averaging the explanations scores after permuting n_perms times the input data\n",
    "\n",
    "equivariant_gradientSHAP = equivariant_explainer(model=gnn, original_explainer=gradientSHAP, n_perms=50)\n",
    "\n",
    "robustness_scores  = equivariance_robustness(testloader, equivariant_gradientSHAP)\n",
    "\n",
    "print('Mean Equivariance Robustness of GradientSHAP after correction:', robustness_scores.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_compare = {\n",
    "    'GradientSHAP': results['GradientSHAP_zeros'],\n",
    "    'equivariant_GradientSHAP': robustness_scores\n",
    "}\n",
    "\n",
    "results_compare = pd.DataFrame(results_compare)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(data=results_compare, ax=ax)\n",
    "\n",
    "ax.set_ylabel('Explanation Equivariance')\n",
    "\n",
    "fig.savefig('compare_gradientSHAP.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are in line with what was reported on the paper. GradientSHAP is the only attribution explainer which produce explanations which are not equivariant with respect to a node permutation with both a baseline tensor of zeros (as in the original paper) and a baseline tensor of ones.\n",
    "\n",
    "The two explainers which I introduced in the benchmark, GNNExplainer and Deconvolution, prove to be exactly robust with respect to the equivariance metric. While all the other explainers are based on gradients, GNNExplainer is a perturbation explainer which shows that also this category can produce robust explanations.\n",
    "\n",
    "Regarding GradientSHAP, it's interesting that changing the baseline improve the results: it could be that choosing the right baseline may allow to obtain even more robust explanations. However, by following the paper guidelines and enforcing the equivariance of the explainers, we can always produce equivariant explanations even from GradientSHAP."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
